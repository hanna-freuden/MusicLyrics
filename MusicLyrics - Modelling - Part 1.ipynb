{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple logistic regression with lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_pickle('df_music'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5100 entries, 0 to 5099\n",
      "Data columns (total 29 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Rank              5100 non-null   int64  \n",
      " 1   Song              5100 non-null   object \n",
      " 2   Artist            5100 non-null   object \n",
      " 3   Year              5100 non-null   int64  \n",
      " 4   Lyrics            4913 non-null   object \n",
      " 5   Source            4913 non-null   float64\n",
      " 6   Artists clean     5100 non-null   object \n",
      " 7   artist_song1      5100 non-null   object \n",
      " 8   songs_clean       5100 non-null   object \n",
      " 9   artist_song2      5100 non-null   object \n",
      " 10  danceability      5083 non-null   object \n",
      " 11  energy            5083 non-null   object \n",
      " 12  key               5083 non-null   object \n",
      " 13  loudness          5083 non-null   object \n",
      " 14  mode              5083 non-null   object \n",
      " 15  speechiness       5083 non-null   object \n",
      " 16  acousticness      5083 non-null   object \n",
      " 17  instrumentalness  5083 non-null   object \n",
      " 18  liveness          5083 non-null   object \n",
      " 19  valence           5083 non-null   object \n",
      " 20  tempo             5083 non-null   object \n",
      " 21  type              5083 non-null   object \n",
      " 22  id                5083 non-null   object \n",
      " 23  uri               5083 non-null   object \n",
      " 24  track_href        5083 non-null   object \n",
      " 25  analysis_url      5083 non-null   object \n",
      " 26  duration_ms       5083 non-null   object \n",
      " 27  time_signature    5083 non-null   object \n",
      " 28  error             1 non-null      object \n",
      "dtypes: float64(1), int64(2), object(26)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100, 29)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of remaining songs is:  4897\n"
     ]
    }
   ],
   "source": [
    "# drop rows with missing values\n",
    "\n",
    "df = df[df.Lyrics != \" NA \"]\n",
    "df.dropna( how='any', subset=['Lyrics'], inplace=True)\n",
    "#reset index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print(\"The number of remaining songs is: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate some lyrics features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics=[]\n",
    "\n",
    "for lyric in df.Lyrics: \n",
    "    lyric_string=re.sub('[^A-Za-z]+', ' ', lyric)\n",
    "    lyrics_string = re.sub('/\\s\\s+/g', ' ', lyric)\n",
    "    lyrics.append(lyric_string.lstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sugar pie honey bunch you know that i love you i cant help myself i love you and nobody elsein and out my life you come and you go leaving just your picture behind and i kissed it a thousand timeswhen you snap your finger or wink your eye i come arunning to you im tied to your apron strings and theres nothing that i can docant help myself no i cant help myselfsugar pie honey bunch im weaker than a man should be i cant help myself im a fool in love you seewanna tell you i dont love you tell you that were through and ive tried but every time i see your face i get all choked up insidewhen i call your name girl it starts the flame burning in my heart tearing it all apart no matter how i try my love i cannot hidecause sugar pie honey bunch you know that im weak for you cant help myself i love you and nobody elsesugar pie honey bunch do anything you ask me to cant help myself i want you and nobody elsesugar pie honey bunch you know that i love you i cant help myself i cant help myself '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply wordninja as some lyrics have words crunched together in one string\n",
    "lyrics_clean=[]\n",
    "for lyric in lyrics :\n",
    "    string=wordninja.split(lyric)\n",
    "    title=\"\"\n",
    "    for s in string:\n",
    "        title+=s+\" \" \n",
    "    lyrics_clean.append(title.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to df\n",
    "df['lyrics_clean']=lyrics_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lemmatizer and tokenizer\n",
    "# apply word tokenizer, delete stopwords, and apply lemmatizer\n",
    "tokens=[]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for row in lyrics_clean:\n",
    "    row_tokens=word_tokenize(row)\n",
    "    filtered_sent = [w for w in row_tokens if not w.lower() in stop_words]\n",
    "    stemmed = [lemmatizer.lemmatize(word) for word in filtered_sent]\n",
    "    tokens.append(stemmed)\n",
    "df['tokens']=tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16118"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy(tokens):\n",
    "    return tokens\n",
    "\n",
    "cv = CountVectorizer(\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "    )  \n",
    "\n",
    "x = cv.fit_transform(tokens)\n",
    "words = cv.get_feature_names()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply tfidf vectorizer\n",
    "# Create the tf-idf representation using the bag-of-words matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transform = TfidfTransformer(norm=None)\n",
    "X_tfidf = tfidf_transform.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(preprocessor=<function dummy_fun at 0x0000016B322453A0>,\n",
       "                token_pattern=None,\n",
       "                tokenizer=<function dummy_fun at 0x0000016B322453A0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transform = text.TfidfTransformer(norm=None)\n",
    "X_tfidf = tfidf_transform.fit_transform(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save labels: ranking<50=1, 0 otherwise\n",
    "y=pd.cut(df.Rank,bins=[0,50,100],labels=['top 50', 'bottom 50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make test_train_split\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def simple_logistic_classify(X_train, y_train, X_test, y_test, _C=1.0):\n",
    "    model = LogisticRegression(C=_C,  max_iter=10000).fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Test Score with', score)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with 0.5064935064935064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_logistic_classify(X_train, y_train, X_test, y_test, _C=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
